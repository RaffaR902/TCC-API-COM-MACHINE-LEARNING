{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ee2435",
   "metadata": {},
   "source": [
    "# 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4773c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas padrão\n",
    "import os                     # Manipulação de caminhos e arquivos\n",
    "import locale                 # Para configuração de locale (ex.: formatação BRL)\n",
    "import numpy as np            # Operações numéricas e vetoriais\n",
    "import pandas as pd           # Manipulação e análise de dados em DataFrames\n",
    "from typing import Dict, Any  # Tipagem opcional para funções\n",
    "\n",
    "\n",
    "# SCIKIT-LEARN — Modelos, validação e pré-processamento\n",
    "from sklearn.model_selection import train_test_split, cross_val_score    # Divisão treino/teste e validação cruzada\n",
    "from sklearn.compose import ColumnTransformer                            # Aplica transformações diferentes por coluna\n",
    "from sklearn.pipeline import Pipeline                                    # Encadeia etapas (preprocessamento → modelo)\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder          # Normalização e codificação categórica\n",
    "from sklearn.metrics import (mean_absolute_error, r2_score, \n",
    "                             make_scorer, mean_squared_log_error)        # Métricas de avaliação\n",
    "from sklearn.cluster import KMeans                                       # Agrupamento para criar clusters de bairros\n",
    "from sklearn.linear_model import LinearRegression                        # Modelo linear de baseline\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor  # Modelos baseados em árvores\n",
    "\n",
    "\n",
    "# XGBOOST — Modelo gradient boosting avançado\n",
    "from xgboost import XGBRegressor  # Um dos melhores modelos para dados tabulares\n",
    "\n",
    "\n",
    "# CATEGORY ENCODERS — Codificadores avançados\n",
    "from category_encoders import TargetEncoder  # Encoding baseado no target (bom para categorias com muitas classes)\n",
    "\n",
    "\n",
    "# JOBLIB — Salvamento de modelos\n",
    "import joblib  # Permite salvar pipelines/modelos treinados para uso posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc628ad",
   "metadata": {},
   "source": [
    "# 2) Configurações e utilitários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18349f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../Dados/imoveis_venda_filtrado.csv' # Caminho do arquivo CSV contendo os dados dos imóveis.\n",
    "\n",
    "MODEL_OUT = 'pipeline_final.joblib' # Nome do arquivo onde será salvo o pipeline final treinado (modelo + pré-processamento).\n",
    "\n",
    "RANDOM_STATE = 42 # Garantir reprodutibilidade dos resultados.\n",
    "\n",
    "N_JOBS = -1 # Número de núcleos da CPU utilizados em paralelização (-1 = usar todos disponíveis).\n",
    "\n",
    "\n",
    "#  Configurar formatação numérica BR\n",
    "locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')          # Tenta configurar o locale para pt_BR para formatação de números e moedas.\n",
    "pd.options.display.float_format = 'R$ {:,.2f}'.format   # Altera a formatação padrão de floats do pandas para exibir como valores monetários BR.\n",
    "\n",
    "\n",
    "#  Métrica RMSLE (Root Mean Squared Logarithmic Error)\n",
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula RMSLE garantindo que os valores negativos sejam truncados para zero.\n",
    "    Isso evita erros de logaritmo negativos.\n",
    "    RMSLE é útil quando queremos punir proporcionalmente erros relativos.\n",
    "    \"\"\"\n",
    "\n",
    "    # Evita valores negativos antes de aplicar o log\n",
    "    y_true = np.maximum(0, y_true)\n",
    "    y_pred = np.maximum(0, y_pred)\n",
    "\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "# Scorer do scikit-learn para usar o RMSLE em validação cruzada.\n",
    "rmsle_scorer = make_scorer(lambda y_true, y_pred: -rmsle(y_true, y_pred)) # O scikit-learn maximiza scores, então colocamos sinal negativo.\n",
    "\n",
    "\n",
    "#  Função auxiliar para imprimir resultados formatados\n",
    "def print_results(df_results: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Exibe uma tabela de resultados (DF) formatada.\n",
    "    Caso existam colunas de valores monetários ou métricas,\n",
    "    elas são formatadas para melhorar a leitura.\n",
    "    \"\"\"\n",
    "    if 'MAE (R$)' in df_results.columns:\n",
    "        print(\n",
    "            df_results.to_string(\n",
    "                formatters={\n",
    "                    'MAE (R$)': 'R$ {:,.2f}'.format,\n",
    "                    'R²': '{:.3f}'.format\n",
    "                },\n",
    "                index=False\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9451722",
   "metadata": {},
   "source": [
    "# 3) Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f747afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados de: ../Dados/imoveis_locacao_filtrado.csv\n",
      "Dados carregados com sucesso. Linhas: 853\n",
      "          tipo                  bairro     cidade objetivo  area_util  \\\n",
      "0         casa          americanopolis  são paulo  Locação   R$ 40.00   \n",
      "1         casa         vila_gumercindo  são paulo  Locação   R$ 25.00   \n",
      "2         casa         vila_gumercindo  são paulo  Locação   R$ 25.00   \n",
      "3         casa            vila_fachini  são paulo  Locação   R$ 50.00   \n",
      "4  apartamento  jardim_miriam_zona_sul  são paulo  Locação   R$ 30.00   \n",
      "\n",
      "   quartos  suites  vagas     preco  \n",
      "0        1       0      0 R$ 800.00  \n",
      "1        1       0      0 R$ 850.00  \n",
      "2        1       0      0 R$ 850.00  \n",
      "3        1       0      0 R$ 850.00  \n",
      "4        1       0      0 R$ 850.00  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 853 entries, 0 to 852\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   tipo       853 non-null    object \n",
      " 1   bairro     853 non-null    object \n",
      " 2   cidade     853 non-null    object \n",
      " 3   objetivo   853 non-null    object \n",
      " 4   area_util  853 non-null    float64\n",
      " 5   quartos    853 non-null    int64  \n",
      " 6   suites     853 non-null    int64  \n",
      " 7   vagas      853 non-null    int64  \n",
      " 8   preco      853 non-null    float64\n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 60.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Carregando dados de:\", DATA_PATH) # Exibe o caminho do arquivo que será carregado\n",
    "\n",
    "try:\n",
    "    # Tenta carregar o arquivo CSV contendo os dados dos imóveis\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "    # Confirma que o carregamento foi bem-sucedido e mostra o número total de linhas\n",
    "    print(\"Dados carregados com sucesso. Linhas:\", len(df))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # Caso o arquivo não exista no caminho especificado, lança um erro mais claro\n",
    "    raise FileNotFoundError(f\"Arquivo não encontrado: {DATA_PATH}\")\n",
    "\n",
    "\n",
    "print(df.head()) # Mostra as primeiras linhas do dataframe para uma visão rápida das colunas e estrutura\n",
    "\n",
    "print(df.info()) # Exibe informações gerais: tipos de dados, quantidade de valores não nulos e uso de memória"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa036e2",
   "metadata": {},
   "source": [
    "# 4) Limpeza e engenharia básica de features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf496b8",
   "metadata": {},
   "source": [
    "### 4.1 Features novas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria variável binária indicando se o imóvel possui ao menos 1 suíte\n",
    "df['tem_suite'] = (df['suites'] > 0).astype(int)\n",
    "\n",
    "# Cria variável binária indicando se o imóvel possui vaga de garagem\n",
    "df['tem_vaga'] = (df['vagas'] > 0).astype(int)\n",
    "\n",
    "# Calcula quantos metros quadrados há por quarto\n",
    "# Quando quartos = 0, substituímos por NaN para evitar divisão por zero\n",
    "df['area_por_quarto'] = df['area_util'] / df['quartos'].replace(0, np.nan)\n",
    "\n",
    "# Para imóveis sem quartos, usamos a própria área do imóvel como fallback\n",
    "df['area_por_quarto'] = df['area_por_quarto'].fillna(df['area_util'])\n",
    "\n",
    "# Calcula a proporção de suítes por quarto (medida de \"sofisticação\")\n",
    "# Divide por quartos substituindo 0 por NaN para não estourar\n",
    "df['proporcao_suites'] = df['suites'] / df['quartos'].replace(0, np.nan)\n",
    "\n",
    "# Imóveis com 0 quartos ou onde a divisão não faz sentido recebem valor 0\n",
    "df['proporcao_suites'] = df['proporcao_suites'].fillna(0)\n",
    "\n",
    "# Aplica transformação logarítmica ao preço (log1p evita problemas com valores 0)\n",
    "# Melhora distribuição, reduz efeito de outliers e ajuda modelos a convergir melhor\n",
    "df['preco_log'] = np.log1p(df['preco'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a80858",
   "metadata": {},
   "source": [
    "### 4.2 Binning para stratify na divisão treino/teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be6a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering concluída. Exemplo:\n",
      "             preco  preco_log  area_util  area_por_quarto\n",
      "count    R$ 853.00  R$ 853.00  R$ 853.00        R$ 853.00\n",
      "mean   R$ 5,673.15    R$ 8.32  R$ 126.19         R$ 50.61\n",
      "std    R$ 5,575.40    R$ 0.78  R$ 111.32         R$ 28.51\n",
      "min      R$ 800.00    R$ 6.69   R$ 15.00         R$ 15.00\n",
      "25%    R$ 2,400.00    R$ 7.78   R$ 49.00         R$ 33.33\n",
      "50%    R$ 3,900.00    R$ 8.27   R$ 85.00         R$ 44.00\n",
      "75%    R$ 6,930.00    R$ 8.84  R$ 165.00         R$ 60.00\n",
      "max   R$ 55,000.00   R$ 10.92  R$ 900.00        R$ 275.00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Criar a variável preco_bin para representar faixas de preço.\n",
    "Isso pode ajudar alguns modelos a capturar padrões não lineares.\n",
    "Usar qcut porque ele divide os dados em quantis — criando bins com\n",
    "quantidade de amostras aproximadamente igual em cada faixa.\n",
    "\"\"\"\n",
    "try:\n",
    "    df['preco_bin'] = pd.qcut(df['preco'], q=10, duplicates='drop', labels=False)\n",
    "except Exception:\n",
    "    \"\"\"\n",
    "    Caso qcut falhe (por valores duplicados ou distribuição estranha),\n",
    "    usamos cut com intervalos fixos, que cria bins de mesmo tamanho em valor,\n",
    "    mas não necessariamente com o mesmo número de amostras.\n",
    "    \"\"\"\n",
    "    df['preco_bin'] = pd.cut(df['preco'], bins=10, labels=False)\n",
    "\n",
    "# Visualização rápida das novas features para ver se estão dentro do esperado\n",
    "print('Feature engineering concluída. Exemplo:')\n",
    "print(df[['preco', 'preco_log', 'area_util', 'area_por_quarto']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f3aa6f",
   "metadata": {},
   "source": [
    "# 5) Definir X, y e dividir treino/teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7499445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split concluído. Treino: 682, Teste: 171\n"
     ]
    }
   ],
   "source": [
    "# Lista de features numéricas, incluindo atributos originais e novas variáveis criadas (feature engineering)\n",
    "# Elas ajudam o modelo a capturar melhor o tamanho, composição e proporções do imóvel.\n",
    "features_numericas = [\n",
    "    'area_util', 'quartos', 'suites', 'vagas',\n",
    "    'tem_suite', 'tem_vaga',                  # variáveis binárias indicando presença de suíte e vaga\n",
    "    'area_por_quarto', 'proporcao_suites'     # proporções que ajudam a medir qualidade dos cômodos\n",
    "]\n",
    "\n",
    "# Variáveis categóricas com poucas categorias → serão codificadas com One-Hot Encoding\n",
    "categorical_low = ['tipo', 'cidade', 'objetivo']\n",
    "\n",
    "# Variável categórica com muitas categorias → será tratada via target encoding\n",
    "categorical_high = ['bairro']\n",
    "\n",
    "# Conjunto total de features categóricas\n",
    "features_categoricas = categorical_low + categorical_high\n",
    "\n",
    "\n",
    "# Define X (features) e y (target transformado em log)\n",
    "X = df[features_numericas + features_categoricas]\n",
    "y = df['preco_log']\n",
    "\n",
    "\n",
    "# Split train/test:\n",
    "# - 80% treino, 20% teste\n",
    "# - estratificação por preco_bin para manter a distribuição de faixas de preço\n",
    "# - também retornamos os índices originais, úteis para juntar resultados depois\n",
    "X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(\n",
    "    X, y, df.index,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=df['preco_bin']\n",
    ")\n",
    "\n",
    "print(f\"Split concluído. Treino: {len(X_train)}, Teste: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f288d45",
   "metadata": {},
   "source": [
    "# 6) Pré-processamento e pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d457489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pré-processamento configurado com estratégia: onehot\n"
     ]
    }
   ],
   "source": [
    "# PRÉ-PROCESSAMENTO — Two modes:\n",
    "# A) OneHot completo\n",
    "# B) OneHot (tipo, objetivo, cidade) + Target Encoding em bairro\n",
    "#\n",
    "# A ideia é permitir comparar duas estratégias diferentes de tratamento \n",
    "# das variáveis categóricas:\n",
    "#   - OneHot: funciona bem quando as categorias não são muitas\n",
    "#   - Target Encoding: melhor para categorias com muitos valores distintos (ex: bairros)\n",
    "\n",
    "\n",
    "STRATEGIA_CATEGORICA = \"onehot\"  \n",
    "# opções:\n",
    "# \"onehot\" → One-hot em TODAS as categorias\n",
    "# \"target\" → One-hot para categorias simples + Target Encoding para bairro\n",
    "\n",
    "\n",
    "# Listas de variáveis por tipo\n",
    "# categorias de baixa cardinalidade = poucas categorias → OneHot funciona bem\n",
    "categoricas_baixa_card = ['tipo', 'cidade', 'objetivo']\n",
    "\n",
    "# variável de alta cardinalidade = MUITOS bairros diferentes → pode gerar sparse demais se usar OneHot\n",
    "categoria_alta_card = ['bairro']\n",
    "\n",
    "# variáveis numéricas (já definidas anteriormente no código)\n",
    "numericas = features_numericas\n",
    "\n",
    "\n",
    "# Pipeline 1 — One-Hot completo\n",
    "if STRATEGIA_CATEGORICA == \"onehot\":\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            # Normalização para variáveis numéricas\n",
    "            ('num', StandardScaler(), numericas),\n",
    "\n",
    "            # OneHotEncoder para todas as categorias, incluindo bairro\n",
    "            # handle_unknown='ignore' evita erros com categorias novas no futuro\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), \n",
    "             categoricas_baixa_card + categoria_alta_card)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "\n",
    "# Pipeline 2 — Target Encoding para bairros\n",
    "elif STRATEGIA_CATEGORICA == \"target\":\n",
    "    \n",
    "    # Pipeline simples para OneHot\n",
    "    onehot_pipe = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    # Pipeline para TargetEncoding\n",
    "    # smoothing controla o \"peso\" da média global para evitar overfitting\n",
    "    target_pipe = Pipeline([\n",
    "        ('target', TargetEncoder(smoothing=0.3)) \n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            # Normalização das numéricas\n",
    "            ('num', StandardScaler(), numericas),\n",
    "\n",
    "            # OneHot apenas nas categorias pequenas\n",
    "            ('onehot_low_card', onehot_pipe, categoricas_baixa_card),\n",
    "\n",
    "            # Target Encoding apenas para bairro\n",
    "            # (reduz sparsidade e ajuda modelos com poucos dados)\n",
    "            ('target_bairro', target_pipe, categoria_alta_card)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"STRATEGIA_CATEGORICA deve ser 'onehot' ou 'target'.\")\n",
    "\n",
    "print(\"Pré-processamento configurado com estratégia:\", STRATEGIA_CATEGORICA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d129b6c8",
   "metadata": {},
   "source": [
    "# 7) Funções auxiliares para treino/avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9824ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_pipeline(pipeline: Pipeline, X_train, y_train, X_test, y_test, tag: str = None):\n",
    "    \"\"\"Treina, prediz e retorna métricas em escala original (R$).\"\"\"\n",
    "    \n",
    "    # Treina o pipeline completo (pré-processamento + modelo)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predições em escala log (porque treinamos com log(preço))\n",
    "    y_pred_log = pipeline.predict(X_test)\n",
    "\n",
    "    # Converte as previsões de volta para a escala original (R$)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    # Também converte o y_test (que está em log) para escala original\n",
    "    y_true = np.expm1(y_test)\n",
    "\n",
    "    # Calcula MAE em reais — métrica mais intuitiva\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # R² na escala original, indicando o quanto o modelo explica da variância dos preços\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # RMSLE — útil para comparar erros relativos em preços\n",
    "    rmsle_val = rmsle(y_true, y_pred)\n",
    "\n",
    "    # Retorna métricas + previsões para análises posteriores\n",
    "    return {'Modelo': tag or 'modelo', 'MAE (R$)': mae, 'R²': r2, 'RMSLE': rmsle_val, 'pred': y_pred}\n",
    "\n",
    "\n",
    "# Cross-validation usando MAE em log-scale (mais estável do que MAE direto em R$)\n",
    "def cross_val_mae_log(estimator, X, y, cv=5):\n",
    "    # Usa MAE (log) negativo porque cross_val_score maximiza a métrica\n",
    "    scores = cross_val_score(estimator, X, y, cv=cv, scoring='neg_mean_absolute_error', n_jobs=N_JOBS)\n",
    "    # Retorna a média positiva e o desvio padrão dos folds\n",
    "    return -np.mean(scores), np.std(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10339b92",
   "metadata": {},
   "source": [
    "# 8) Modelos base (pipelines completos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dccfba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Validação Cruzada (MAE em log-scale) ---\n",
      "Regressão Linear: MAE médio (log) = 0.2726 (+/- 0.0299)\n",
      "Random Forest: MAE médio (log) = 0.2813 (+/- 0.0332)\n",
      "XGBoost: MAE médio (log) = 0.2874 (+/- 0.0329)\n"
     ]
    }
   ],
   "source": [
    "# Dicionário para armazenar os modelos\n",
    "models = {}\n",
    "\n",
    "# 1. Regressão Linear\n",
    "# Pipeline = pré-processamento + modelo final\n",
    "# A Regressão Linear serve como baseline simples e interpretável.\n",
    "models['Regressão Linear'] = Pipeline([\n",
    "    ('preprocessor', preprocessor),         # aplica encoders, escalonamento, etc.\n",
    "    ('model', LinearRegression())           # modelo linear simples\n",
    "])\n",
    "\n",
    "\n",
    "# 2. Random Forest Regressor\n",
    "# Modelo baseado em muitas árvores de decisão.\n",
    "# Lida bem com não linearidades e interações automaticamente.\n",
    "models['Random Forest'] = Pipeline([\n",
    "    ('preprocessor', preprocessor),         \n",
    "    ('model', RandomForestRegressor(\n",
    "        n_estimators=200,                   # número de árvores\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=N_JOBS                       # paralelismo para acelerar\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# 3. XGBoost Regressor\n",
    "# Modelo baseado em boosting (árvores em sequência).\n",
    "# Geralmente fornece excelente performance em dados tabulares.\n",
    "models['XGBoost'] = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        objective='reg:squarederror',       # função de erro padrão para regressão\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=N_JOBS\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# Avaliação rápida com validação cruzada (5-fold)\n",
    "# A métrica MAE é calculada usando os valores em escala LOG.\n",
    "# Isso estabiliza outliers e melhora a robustez.\n",
    "print('\\n--- Validação Cruzada (MAE em log-scale) ---')\n",
    "for name, pipe in models.items():\n",
    "    mae_log_mean, mae_log_std = cross_val_mae_log(pipe, X_train, y_train, cv=5)\n",
    "    print(f\"{name}: MAE médio (log) = {mae_log_mean:.4f} (+/- {mae_log_std:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28927bcf",
   "metadata": {},
   "source": [
    "# 9) Treinar modelos base e avaliar em escala original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9addcae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados Teste (Base) ---\n",
      "          Modelo    MAE (R$)    R²   RMSLE\n",
      "Regressão Linear R$ 1,326.14 0.732 R$ 0.31\n",
      "         XGBoost R$ 1,670.21 0.621 R$ 0.36\n",
      "   Random Forest R$ 1,723.14 0.517 R$ 0.36\n"
     ]
    }
   ],
   "source": [
    "# Lista para guardar os resultados de cada modelo\n",
    "results = []\n",
    "\n",
    "# Loop pelos modelos/pipelines definidos anteriormente\n",
    "for name, pipe in models.items():\n",
    "\n",
    "    # Avalia o pipeline usando a função personalizada (treino + teste)\n",
    "    # Retorna métricas como MAE, RMSE, R² e previsões\n",
    "    out = avaliar_pipeline(pipe, X_train, y_train, X_test, y_test, tag=name)\n",
    "\n",
    "    # Guarda apenas as métricas (remove 'pred', que contém as previsões)\n",
    "    results.append({k: v for k, v in out.items() if k != 'pred'})\n",
    "\n",
    "\n",
    "# Converte os resultados em DataFrame para organizar e comparar\n",
    "df_results = pd.DataFrame(results).sort_values('MAE (R$)')\n",
    "\n",
    "print('\\n--- Resultados Teste (Base) ---')\n",
    "\n",
    "# Função auxiliar que imprime o DataFrame com formatação amigável\n",
    "print_results(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d980f29a",
   "metadata": {},
   "source": [
    "# 10) Agrupar categorias raras (especialmente bairros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf2dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bairro\n",
      "saude                    80\n",
      "indianopolis             43\n",
      "vila_do_encontro         40\n",
      "vila_guarani_zona_sul    31\n",
      "vila_mariana             30\n",
      "                         ..\n",
      "real_parque               1\n",
      "brooklin_novo             1\n",
      "paineiras_do_morumbi      1\n",
      "brooklin                  1\n",
      "jardim_cordeiro           1\n",
      "Name: count, Length: 113, dtype: int64\n",
      "Categorias restantes em 'bairro': 83\n",
      "bairro\n",
      "saude                    80\n",
      "indianopolis             43\n",
      "vila_do_encontro         40\n",
      "outros                   31\n",
      "vila_guarani_zona_sul    31\n",
      "                         ..\n",
      "vila_gertrudes            2\n",
      "sumarezinho               2\n",
      "parque_colonial           2\n",
      "granja_julieta            2\n",
      "jardim_europa             2\n",
      "Name: count, Length: 83, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mostra quantos registros existem em cada bairro (importante para identificar categorias muito raras)\n",
    "print(df.bairro.value_counts())\n",
    "\n",
    "def reduzir_categorias_raras(df, coluna, minimo=2):\n",
    "    \"\"\"\n",
    "    Agrupa categorias raras em 'outros'.\n",
    "\n",
    "    - Bairros com poucos registros criam sparsidade no One-Hot Encoding\n",
    "    - Isso prejudica modelos lineares e aumenta o risco de overfitting\n",
    "    - Agrupar categorias raras melhora a estabilidade do modelo\n",
    "\n",
    "    Parâmetros:\n",
    "    - coluna: nome da coluna categórica\n",
    "    - minimo: número mínimo de ocorrências para manter a categoria\n",
    "    \"\"\"\n",
    "    contagem = df[coluna].value_counts()\n",
    "    \n",
    "    # Mantém apenas as categorias que aparecem pelo menos 'minimo' vezes\n",
    "    categorias_validas = contagem[contagem >= minimo].index\n",
    "\n",
    "    # Substitui categorias raras por \"outros\"\n",
    "    df[coluna] = df[coluna].apply(lambda x: x if x in categorias_validas else \"outros\")\n",
    "    return df\n",
    "\n",
    "# Padroniza o nome dos bairros: minúsculas e sem espaços extras\n",
    "df[\"bairro\"] = df[\"bairro\"].str.lower().str.strip()\n",
    "\n",
    "# Aplica a redução de categorias (agrupa bairros muito raros em \"outros\")\n",
    "df = reduzir_categorias_raras(df, \"bairro\", minimo=2)\n",
    "\n",
    "# Mostra quantas categorias sobraram após o agrupamento\n",
    "print(\"Categorias restantes em 'bairro':\", df[\"bairro\"].nunique())\n",
    "print(df.bairro.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abacf3e",
   "metadata": {},
   "source": [
    "# 11) Feature Engineering: Interações e novas variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efac005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma feature de interação entre área e quantidade de quartos.\n",
    "# Captura imóveis \"maiores e com muitos quartos\", que tendem a ser mais valorizados.\n",
    "df[\"quartos_area\"] = df[\"quartos\"] * df[\"area_util\"]\n",
    "\n",
    "# Cria interação entre vagas e área, indicando imóveis grandes com várias vagas.\n",
    "df[\"vagas_area\"] = df[\"vagas\"] * df[\"area_util\"]\n",
    "\n",
    "# Mede quão \"espaçosos\" são os quartos em média.\n",
    "df[\"densidade_quartos\"] = df[\"area_util\"] / (df[\"quartos\"] + 0.1) # Usa +0.1 para evitar divisão por zero quando não há quartos.\n",
    "\n",
    "# Razão de suítes por quarto, indicando sofisticação/luxo do imóvel.\n",
    "df[\"suites_ratio\"] = df[\"suites\"] / (df[\"quartos\"] + 0.1) # Usa +0.1 para evitar divisão por zero quando não há quartos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382eb5f4",
   "metadata": {},
   "source": [
    "# 12) Estatísticas por bairro (mean encoding simples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média histórica do bairro\n",
    "# Calcular o preço médio de locação para cada bairro usando toda a base de dados.\n",
    "# Isso cria uma referência do \"nível de preço\" típico de cada região.\n",
    "media_bairro = df.groupby(\"bairro\")[\"preco\"].mean()\n",
    "df[\"preco_medio_bairro\"] = df[\"bairro\"].map(media_bairro)\n",
    "\n",
    "# Desvio do preço do bairro\n",
    "# Esta variável mede o quanto o preço do imóvel está acima ou abaixo da média do bairro.\n",
    "# Serve para capturar anomalias e destacar imóveis muito baratos ou muito caros dentro da sua região.\n",
    "df[\"dif_media_bairro\"] = df[\"preco\"] - df[\"preco_medio_bairro\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d7ce89",
   "metadata": {},
   "source": [
    "# 13) Clusterização de bairros por média de preço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbb9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um dataframe temporário apenas com a média de preço por bairro\n",
    "# Isso reduz variabilidade e permite agrupar bairros por perfil de valor\n",
    "df_temp = media_bairro.reset_index()\n",
    "df_temp.columns = [\"bairro\", \"media_preco\"]\n",
    "\n",
    "# Aplicar KMeans para agrupar bairros em 5 clusters baseados na média de preço\n",
    "# Assim, bairros com valores semelhantes ficam no mesmo grupo\n",
    "kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "df_temp[\"cluster_bairro\"] = kmeans.fit_predict(df_temp[[\"media_preco\"]])\n",
    "\n",
    "# Criar um dicionário {bairro -> cluster}\n",
    "# Depois mapear esses clusters de volta para o dataframe principal\n",
    "map_clusters = df_temp.set_index(\"bairro\")[\"cluster_bairro\"].to_dict()\n",
    "df[\"cluster_bairro\"] = df[\"bairro\"].map(map_clusters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1329f8",
   "metadata": {},
   "source": [
    "# 14) Atualizar a lista de features (inclui cluster e estatísticas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f35f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das variáveis categóricas:\n",
    "# - categorical_low: categorias com poucas variações → podem usar OneHot sem explodir colunas\n",
    "# - categorical_high: categorias com muitas variações (ex.: bairros) → tratadas separadamente\n",
    "categorical_low = ['tipo', 'cidade', 'objetivo']\n",
    "categorical_high = ['bairro']\n",
    "features_categoricas = categorical_low + categorical_high\n",
    "\n",
    "# Lista de variáveis numéricas:\n",
    "# Inclui tanto atributos originais quanto variáveis derivadas (feature engineering)\n",
    "# criadas para capturar relações não lineares e padrões específicos dos bairros.\n",
    "features_numericas = [\n",
    "    'area_util', 'quartos', 'suites', 'vagas',                     # atributos originais\n",
    "    'quartos_area', 'vagas_area', 'densidade_quartos', 'suites_ratio',  # interações e razões\n",
    "    'preco_medio_bairro', 'dif_media_bairro', 'cluster_bairro'     # informações derivadas por bairro\n",
    "]\n",
    "\n",
    "# Conjunto final de features X e variável alvo (log do preço)\n",
    "X = df[features_numericas + features_categoricas]\n",
    "y = df['preco_log']\n",
    "\n",
    "# Divisão treino/teste:\n",
    "# - Mantém 20% para teste\n",
    "# - Usa stratify com preco_bin para garantir distribuição equilibrada dos preços\n",
    "# - Retorna também os índices originais (train_idx, test_idx) para facilitar análises posteriores\n",
    "X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(\n",
    "    X, y, df.index, test_size=0.2, random_state=RANDOM_STATE, stratify=df['preco_bin']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbcb5f8",
   "metadata": {},
   "source": [
    "# 15) Recriar ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e524679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# ColumnTransformer: responsável por aplicar transformações diferentes \n",
    "# para cada grupo de colunas antes de enviar os dados ao modelo.\n",
    "#\n",
    "# - \"cat_low\": categorias com poucas variações (tipo, cidade, objetivo)\n",
    "#              -> recebem OneHotEncoder (gera colunas binárias estáveis)\n",
    "#\n",
    "# - \"cat_high\": categorias com muitas variações (bairro)\n",
    "#               -> também recebem OneHotEncoder, MAS o agrupamento prévio\n",
    "#                 dos bairros raros reduz sparsidade e melhora desempenho\n",
    "#\n",
    "# - \"num\": atributos numéricos (área, quartos, suites, vagas, features criadas)\n",
    "#          -> recebem StandardScaler para colocar tudo na mesma escala\n",
    "#\n",
    "# O ColumnTransformer garante:\n",
    "#    preprocessamento consistente\n",
    "#    integração com o pipeline de ML\n",
    "#    evita vazamento de dados (fit só no treino)\n",
    "# -------------------------------------------------------------------------\n",
    "col_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat_low\", OneHotEncoder(handle_unknown='ignore'), categorical_low),\n",
    "        (\"cat_high\", OneHotEncoder(handle_unknown='ignore'), categorical_high),\n",
    "        (\"num\", StandardScaler(), features_numericas),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9bc31",
   "metadata": {},
   "source": [
    "# 16) Redefinir os modelos (incluindo CatBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELOS UTILIZADOS\n",
    "#\n",
    "# Aqui definimos os modelos de machine learning que serão\n",
    "# treinados com os dados transformados pelo pipeline.\n",
    "#\n",
    "# RandomForest:\n",
    "#   - Modelo baseado em várias árvores de decisão.\n",
    "#   - Funciona bem com dados tabulares.\n",
    "#   - Captura relações não lineares.\n",
    "#   - Não exige muita normalização dos dados.\n",
    "#\n",
    "# XGBoost:\n",
    "#   - Gradient Boosting avançado e muito eficiente.\n",
    "#   - Excelente para dados tabulares com features não lineares.\n",
    "#   - Geralmente apresenta o melhor desempenho em modelos de preço.\n",
    "#   - Usa a perda \"reg:squarederror\" para regressão.\n",
    "#   - eval_metric=\"mae\" faz o treino otimizar erro absoluto,\n",
    "#     o que combina melhor com avaliações em log.\n",
    "#\n",
    "# Ambos recebem random_state para garantir reprodutibilidade.\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "\n",
    "    \"XGBoost\": XGBRegressor(\n",
    "        objective=\"reg:squarederror\",   # função de perda para regressão\n",
    "        eval_metric=\"mae\",              # métrica usada durante treinamento\n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a3b3a",
   "metadata": {},
   "source": [
    "# 17) Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2afc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "tuned_models = {}\n",
    "\n",
    "# RANDOM FOREST — Busca de hiperparâmetros\n",
    "\n",
    "# Aqui definimos um pequeno espaço de busca para o Random Forest.\n",
    "# O objetivo é testar combinações diferentes de número de árvores,\n",
    "# profundidade máxima e mínimo de amostras por split.\n",
    "# O RandomizedSearchCV testa combinações aleatórias desses valores\n",
    "# e encontra o conjunto que produz o menor erro MAE (em validação cruzada).\n",
    "\n",
    "param_rf = {\n",
    "    \"n_estimators\": [200, 400, 800],   # quantidade de árvores\n",
    "    \"max_depth\": [None, 10, 20, 30],   # profundidade máxima da árvore\n",
    "    \"min_samples_split\": [2, 5, 10],   # mínimo de amostras para dividir um nó\n",
    "}\n",
    "\n",
    "rf_search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_rf,\n",
    "    n_iter=10,                          # número de combinações aleatórias testadas\n",
    "    scoring=\"neg_mean_absolute_error\",  # métrica: MAE negativo (quanto maior, melhor)\n",
    "    cv=5,                               # validação cruzada com 5 folds\n",
    "    n_jobs=-1,                          # usa todos os núcleos disponíveis\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Treinamento do random search com os dados processados pelo ColumnTransformer\n",
    "rf_search.fit(col_transformer.fit_transform(X_train), y_train)\n",
    "\n",
    "# Armazena o melhor modelo encontrado\n",
    "tuned_models[\"RandomForest\"] = rf_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# XGBOOST — Busca de hiperparâmetros\n",
    "\n",
    "# O XGBoost costuma ser o modelo mais forte em dados tabulares.\n",
    "# Aqui testamos combinações de:\n",
    "# - número de árvores (n_estimators)\n",
    "# - taxa de aprendizado (learning_rate)\n",
    "# - profundidade máxima das árvores (max_depth)\n",
    "# - fração de amostra por árvore (subsample)\n",
    "\n",
    "# O RandomizedSearchCV encontra os melhores parâmetros usando MAE.\n",
    "\n",
    "param_xgb = {\n",
    "    \"n_estimators\": [300, 600, 1000],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"subsample\": [0.7, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        eval_metric=\"mae\",\n",
    "        random_state=42\n",
    "    ),\n",
    "    param_xgb,\n",
    "    n_iter=10,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Treinamento do random search com dados transformados\n",
    "xgb_search.fit(col_transformer.fit_transform(X_train), y_train)\n",
    "\n",
    "# Armazena o melhor modelo encontrado\n",
    "tuned_models[\"XGBoost\"] = xgb_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed59fd7",
   "metadata": {},
   "source": [
    "# 18) Avaliar novamente com validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1166e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Validação Cruzada Após Melhorias (MAE em log-scale) ---\n",
      "RandomForest: MAE médio (log) = 0.0866 (+/- 0.0135) e R² = 0.9697 (+/- 0.0084)\n",
      "XGBoost: MAE médio (log) = 0.0639 (+/- 0.0078) e R² = 0.9811 (+/- 0.0065)\n",
      "CatBoost: MAE médio (log) = 0.0828 (+/- 0.0086) e R² = 0.9736 (+/- 0.0063)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Validação Cruzada Após Melhorias (MAE em log-scale) ---\")\n",
    "\n",
    "for name, model in tuned_models.items():\n",
    "\n",
    "    # Criamos o pipeline combinando:\n",
    "    # 1) o pré-processamento (one-hot, target encoding, scaling)\n",
    "    # 2) o modelo regressivo ajustado (XGBoost ou RandomForest)\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocess\", col_transformer),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    # Calcula o MAE médio em escala log usando validação cruzada (k=5).\n",
    "    # Isso mede o erro percentual aproximado do modelo, que é mais estável\n",
    "    # e menos sensível a outliers quando usamos log(preço).\n",
    "    mae_log_mean, mae_log_std = cross_val_mae_log(pipe, X_train, y_train, cv=5)\n",
    "\n",
    "    # Calcula também o R² via validação cruzada (k=5).\n",
    "    # O R² mede o quanto o modelo explica da variabilidade dos preços.\n",
    "    r2_scores = cross_val_score(pipe, X_train, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    r2_mean = np.mean(r2_scores)\n",
    "    r2_std = np.std(r2_scores)\n",
    "\n",
    "    # Exibimos as métricas de forma clara para comparação entre modelos.\n",
    "    print(f\"{name}: MAE médio (log) = {mae_log_mean:.4f} (+/- {mae_log_std:.4f}) \"\n",
    "          f\"e R² = {r2_mean:.4f} (+/- {r2_std:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
